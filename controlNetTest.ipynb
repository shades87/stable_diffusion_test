{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dan_d\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers.utils import load_image, make_image_grid\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "original_image = load_image(\n",
    "    \"./dataset/structure_with_cracks0.png\"\n",
    ")\n",
    "\n",
    "image = np.array(original_image)\n",
    "\n",
    "low_threshold = 100\n",
    "high_threshold = 200\n",
    "\n",
    "image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "canny_image = Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\n",
    "import torch\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16, use_safetensors=True)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16, use_safetensors=True\n",
    ")\n",
    "\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.to(\"cuda\")\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\dan_d\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\models\\attention_processor.py:1279: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "100%|██████████| 50/50 [13:39<00:00, 16.39s/it]\n",
      "100%|██████████| 50/50 [14:47<00:00, 17.75s/it]\n",
      "100%|██████████| 50/50 [14:47<00:00, 17.74s/it]\n",
      "100%|██████████| 50/50 [14:47<00:00, 17.75s/it]\n",
      " 48%|████▊     | 24/50 [07:23<08:00, 18.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConcrete with cracks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanny_image\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     make_image_grid([original_image, canny_image, output], rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m     output\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrolnet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\pipelines\\controlnet\\pipeline_controlnet.py:1270\u001b[0m, in \u001b[0;36mStableDiffusionControlNetPipeline.__call__\u001b[1;34m(self, prompt, image, height, width, num_inference_steps, timesteps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, controlnet_conditioning_scale, guess_mode, control_guidance_start, control_guidance_end, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m noise_pred_uncond \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguidance_scale \u001b[38;5;241m*\u001b[39m (noise_pred_text \u001b[38;5;241m-\u001b[39m noise_pred_uncond)\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;66;03m# compute the previous noisy sample x_t -> x_t-1\u001b[39;00m\n\u001b[1;32m-> 1270\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_step_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback_on_step_end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1273\u001b[0m     callback_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\schedulers\\scheduling_unipc_multistep.py:793\u001b[0m, in \u001b[0;36mUniPCMultistepScheduler.step\u001b[1;34m(self, model_output, timestep, sample, return_dict)\u001b[0m\n\u001b[0;32m    791\u001b[0m model_output_convert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_model_output(model_output, sample\u001b[38;5;241m=\u001b[39msample)\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_corrector:\n\u001b[1;32m--> 793\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultistep_uni_c_bh_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis_model_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output_convert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthis_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthis_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msolver_order \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_outputs[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_outputs[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\diffusers\\schedulers\\scheduling_unipc_multistep.py:662\u001b[0m, in \u001b[0;36mUniPCMultistepScheduler.multistep_uni_c_bh_update\u001b[1;34m(self, this_model_output, last_sample, this_sample, order, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m     D1s\u001b[38;5;241m.\u001b[39mappend((mi \u001b[38;5;241m-\u001b[39m m0) \u001b[38;5;241m/\u001b[39m rk)\n\u001b[0;32m    661\u001b[0m rks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 662\u001b[0m rks \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m R \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    665\u001b[0m b \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    output = pipe(\n",
    "        \"Concrete with cracks\", image=canny_image\n",
    "        ).images[0]\n",
    "    make_image_grid([original_image, canny_image, output], rows=1, cols=3)\n",
    "\n",
    "    output.save(\"controlnet\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_image = load_image(\n",
    "    \"./chatgpt_prompt_images/chatprompt2.png\"\n",
    ")\n",
    "\n",
    "image = np.array(chat_image)\n",
    "image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "image = image[:, :, None]\n",
    "image = np.concatenate([image, image, image], axis=2)\n",
    "canny_image = Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [16:11<00:00, 19.43s/it]\n",
      "100%|██████████| 50/50 [14:16<00:00, 17.14s/it]\n",
      "100%|██████████| 50/50 [14:16<00:00, 17.13s/it]\n",
      "100%|██████████| 50/50 [14:16<00:00, 17.13s/it]\n",
      "100%|██████████| 50/50 [14:15<00:00, 17.11s/it]\n",
      "100%|██████████| 50/50 [14:15<00:00, 17.12s/it]\n",
      "100%|██████████| 50/50 [14:16<00:00, 17.12s/it]\n",
      "100%|██████████| 50/50 [14:15<00:00, 17.10s/it]\n",
      "100%|██████████| 50/50 [14:16<00:00, 17.12s/it]\n",
      "100%|██████████| 50/50 [14:16<00:00, 17.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    output = pipe(\n",
    "        \"Generate a realistic image of a concrete building with visible signs of damage, such as spalling, cracks, and weathering.\", image=canny_image\n",
    "        ).images[0]\n",
    "    make_image_grid([original_image, canny_image, output], rows=1, cols=3)\n",
    "\n",
    "    output.save(\"chat_controlnet\"+str(i)+\".jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
